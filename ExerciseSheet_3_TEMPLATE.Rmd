---
title: "Exercise 3"
subtitle: "Fortgeschrittene Statistische Software für NF"
author: "David Fersing (12743059)"
date: "`r Sys.Date()`"
output: distill::distill_article
editor_options: 
  markdown: 
    wrap: 72
---

## General Remarks

-   You can submit your solutions in teams of up to 3 students.
-   Include all your team-member's names and student numbers
    (Matrikelnummern) in the `authors` field.
-   Please use the exercise template document to work on and submit your
    results.
-   Use a level 2 heading for each new exercise and answer each subtask
    next to its bullet points or use a new level 3 heading if you want.
-   Always render the R code for your solutions (`echo=TRUE`) and make
    sure to include the resulting data in your rendered document.
    -   Make sure to not print more than 10 rows of data (unless
        specifically instructed to).
-   Always submit both the rendered document(s) as well as your source
    Rmarkdown or Quarto document. Submit the files separately on moodle,
    **not** as a zip archive.
-   Submission format is HTML. Other formats will lead to a deduction of
    points.

## Exercise 1: Initializing git (4 Points)

For this whole exercise sheet we will be tracking all our changes to it
in git.

a)  Start by initializing a new R project with git support, called
    `2025-exeRcise-sheet-3`. If you forgot how to do this, you can
    follow this
    [guide](https://malikaihle.github.io/Introduction-RStudio-Git-GitHub/rstudio_project.html).
b)  Commit the files generated by Rstudio.
c)  For all of the following tasks in this exercise sheet we ask you to
    always commit your changes after finishing each subtask e.g. create
    a commit after task *1d*, *1e* etc.

Finished

> Note: This applies only to answers that have text or code as their
> answer. If you complete tasks in a different order or forget to commit
> one, this is no problem. If you change your answers you can just
> create multiple commits to track the changes.

d)  Name 2 strengths and 2 weaknesses of git. (Don't forget to create a
    commit after this answer, see *1c*)

Strengths and Weaknesses of Git

Strengths:

-   Distributed Version Control –\> Every developer has a full local
    copy of the repository, enabling offline work and faster operations.

-   Efficient Branching & Merging –\> Lightweight branches allow
    seamless parallel development and easy collaboration.

Weaknesses:

-   Git can be confusing for beginners.

-   Some commands can delete changes if not used carefully.

e)  Knit this exercise sheet. Some new files will automatically be
    generated when knitting the sheet e.g. the HTML page. Ignore these
    files, as we only want to track the source files themselves. You
    can, but don't need to create a `.gitignore` file. Just do not
    commit these files manually.

## Exercise 2: Putting your Repository on GitHub (3 Points)

For this task you will upload your solution to GitHub.

a)  Create a new repository on GitHub in your account named
    `exeRcise-sheet-3`. Make sure you create a **public repository** so
    we are able to see it for grading. Add the link to the repository
    below:
  
HTTPS Link: https://github.com/DavidtheRavinger/exeRcise-sheet-3.git

SSH Link: git@github.com:DavidtheRavinger/exeRcise-sheet-3.git

b)  Push your code to this new repository by copying and executing the
    snippet on github listed under
    `…or push an existing repository from the command line`.
    
I uploaded my code to the new repository by copying and running the snippet shown on GitHub in the terminal.

The code
c)  Regularly push your latest changes to GitHub again and especially do
    so when you are finished with this sheet.

## Exercise 3: Pixar Films (4 Points)

Download the `pixar_films` and `public_response` datasets from the
GitHub repository and track them in git.

Link:
<https://github.com/rfordatascience/tidytuesday/tree/main/data/2025/2025-03-11>

For small datasets like these adding them to git is not a problem.

a)  Load the `pixar_films` dataset into R. Clean the dataset by removing
    films without a title. Inspect the variable `film_rating`. What are
    the possible values and what do they mean? Create a factor variable
    for the film rating. Why is this appropriate?
    
```{r}
library(tidyverse)

pixar_films <- read_csv("data/pixar_films.csv")

pixar_films_clean <- pixar_films %>%
  filter(!is.na(film))

# inspect the variable fiml_rating and look up possible values
unique(pixar_films_clean$film_rating)


pixar_films_clean <- pixar_films_clean %>%
  mutate(film_rating_factor = as.factor(film_rating))




```
The meaning of these values:

G — General Audience (suitable for all ages)
PG — Parental Guidance Suggested (some material may not be suitable for children)

Based on the Motion Picture Association film rating system there are these options: G, PG, PG-13 (Parents strongly cautioned – some material may be inappropriate for children under 13.), R (Restricted – under 17 requires accompanying parent or adult guardian.), NC-17 (No one 17 and under admitted – strictly for adults only.) and NA.

Why is this appropriate?
-> Creating a factor variable for film rating is appropriate because film ratings are categorical data with a natural order. Using an ordered factor allows R to correctly interpret and analyze these categories, enabling meaningful summaries and visualizations that respect their hierarchy.

<!-- -->

b)  Inspect the film titles manually. Which films form a film series? A
    film series can be identified by a common word in the titles of the
    films, often in conjunction with a number in the title,
    e.g. "Despicable Me" and "Despicable Me 2". Create a dataframe which
    displays a list of the different series with the titles of the films
    and how many films belong to the series. Output the dataframe.
    
Which films form a film series?
    
Toy Story series:
Toy Story (1995), Toy Story 2 (1999), Toy Story 3 (2010), Toy Story 4 (2019)

Cars series:
Cars (2006), Cars 2 (2011), Cars 3 (2017)

Monsters series:
Monsters, Inc. (2001), Monsters University (2013) — Prequel to Monsters, Inc.

Finding series:
Finding Nemo (2003), Finding Dory (2016)

The Incredibles series:
The Incredibles (2004), Incredibles 2 (2018)
    
```{r}

keywords <- c("Toy Story", "Cars", "Monsters", "Finding", "Incredibles")

get_series <- function(title, keywords) {
  for (k in keywords) {
    if (str_detect(title, fixed(k))) {
      return(k)
    }
  }
  return(NA_character_)
}

  
pixar_films_clean <- pixar_films_clean %>%
  rowwise() %>%
  mutate(series = get_series(film, keywords)) %>%
  ungroup()

series_summary <- pixar_films_clean %>%
  filter(!is.na(series)) %>%
  group_by(series) %>%
  summarise(
    films = paste(film, collapse = ", "),
    count = n()
  )

knitr::kable(series_summary)
```



c)  Load the `public_response` dataframe into R. Convert the
    `cinema_score` variable into a factor while ensuring the factor
    levels are defined in ascending order, from the lowest to the
    highest score. Combine `public_response` with the `pixar_films`
    dataset using an appropriate merge variable.
    
```{r}
public_response <- read_csv("data/public_response.csv")

score_levels <- c("F", "D-", "D", "D+", "C-", "C", "C+", "B-", "B", "B+", "A-", "A", "A+")

public_response <- public_response %>%
  mutate(cinema_score = factor(cinema_score, levels = score_levels, ordered = TRUE))

combined_data <- left_join(pixar_films, public_response, by = "film")

```


d)  Choose one of the variables representing the public response and
    create a bar plot for the films belonging to a series. Here are the
    details of the plot:

    -   The film series are represented on the x-axis.
    -   Your chosen public response variable is displayed on the y-axis.
    -   Each film in the series is represented as a separate bar. Bars
        are grouped by film under their respective series on the x-axis.
        Order the bars within a series according to the release date of
        the films.
    -   A title and axis labels for context.

    What do you notice when comparing the scores of the films in a
    series? Do you see any patterns?
    
```{r}
# Liste von Keywords zur Serienerkennung
keywords <- c("Toy Story", "Cars", "Monsters", "Finding", "Incredibles")

# Funktion zum Erkennen der Serie
get_series <- function(title) {
  matched <- keywords[str_detect(title, fixed(keywords))]
  if (length(matched) == 0) return(NA_character_)
  return(matched[1])
}

combined_data <- combined_data %>%
  rowwise() %>%
  mutate(series = get_series(film)) %>%
  ungroup()

series_films <- combined_data %>%
  filter(!is.na(series))

series_films <- series_films %>%
  arrange(series, release_date) %>%
  mutate(film = factor(film, levels = unique(film)))

# Legendenlabels erstellen: "Serie (Film1, Film2, ...)"
legend_labels <- series_films %>%
  group_by(series) %>%
  summarise(films = paste(film, collapse = ", ")) %>%
  mutate(label = paste0(series, " (", films, ")")) %>%
  deframe()

series_colors <- c(
  "Toy Story" = "#1f77b4",
  "Cars" = "#ff7f0e",
  "Monsters" = "#2ca02c",
  "Finding" = "#d62728",
  "Incredibles" = "#9467bd"
)



# Plot
ggplot(series_films, aes(x = series, y = rotten_tomatoes, fill = series, group = film)) +
  geom_bar(aes(group = film), stat = "identity", position = position_dodge(width = 1.0)) +
  scale_fill_manual(values = series_colors, labels = legend_labels) +
  labs(
    title = "Rotten Tomatoes Scores for Pixar Film Series",
    x = "Film Series",
    y = "Rotten Tomatoes Score",
    fill = "Series (Films)",
    caption = "Bars corresponding to films are ordered from left to \nright in ascending release date order, corresponding to the order in the legend"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.caption.position = "plot",
    plot.caption = element_text(hjust = 0.5, face = "italic", size = 9)
  )

```
Answer: Yes, I can observe a pattern: in all series, the films tend to have lower scores the older their release date is — except for the Cars series, where Cars 3 actually received a higher score than Cars 2.

## Exercise 4: Open Analysis (4 points)

This exercise is a bit more open-ended. You can choose any dataset from
[Our World in Data](https://ourworldindata.org/) and analyze it, while
determining the research question yourself.

a)  Go to <https://github.com/owid/owid-datasets/tree/master/datasets>
    and choose a dataset that interests you. You can have a look at
    <https://ourworldindata.org/> to gather some inspiration.
    
-> Alcohol consumption since 1890 (Alexander & Holmes, 2017).csv

b)  Download the dataset and track it in git.




c)  Put the name / title of the dataset and a link to it below.

-   Dataset Name: Alcohol consumption since 1890 (Alexander & Holmes, 2017)
-  Link: https://github.com/owid/owid-datasets/tree/master/datasets/Alcohol%20consumption%20since%201890%20(Alexander%20%26%20Holmes%2C%202017)

d)  Come up with a (research) question you want to answer with the data
    and briefly explain why you believe this is an interesting question
    within one sentence. It should be a question that can be answered
    with the dataset and using R.
    
How has per capita alcohol consumption in Germany evolved from 1890 to 2014 compared to the United-States, Netherlands, Italy and Australia?

-> It is common knowledge that alcohol consumption is highly unhealthy for us, therefore it is important to reflect on the trend of our consumption, especially in comparison to other countries with different drinking cultures and policies. 

e)  Use R to answer your chosen question. Please limit your analysis to
    the functions and techniques we have covered so far in the course.
    You are **not expected** to use advanced statistical models or
    external packages which haven't been introduced.
    
```{r}
library(kableExtra)

alcohol_data <- read_csv("data/Alcohol consumption since 1890 (Alexander & Holmes, 2017).csv")

countries = c("United States", "Netherlands", "Italy", "Australia", "Germany")    
    
summary_data <- alcohol_data %>%
  filter(Entity %in% countries) %>%
  group_by(Entity) %>%
   rename(alcohol_consumption = `Alcohol consumption since 1890 (Alexander & Holmes, 2017)`) %>%
  summarise(
    `value 1890` = alcohol_consumption[which(Year == 1890)],
    `value 2014` = alcohol_consumption[which(Year == 2014)],
    `percental change from 1890 to 2014` = ((`value 2014` / `value 1890`) - 1) * 100,
    `mean rate of change per decade` = (`value 2014` - `value 1890`) / ((2014-1890) / 10),
    cor = cor(alcohol_consumption, Year),
    `Year with max` = Year[which.max(alcohol_consumption)],
    `max value` = max(alcohol_consumption)
  ) %>%
  mutate(across(where(is.numeric), ~ round(.x, 3)))

summary_data %>%
  kable(format = "html", align = "c", caption = "Summary of Alcohol Consumption (1890–2014)") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = FALSE)

```
German per capita alcohol consumption changed very little from 1890 to 2014. It reached a higher peak in 1970, after which consumption declined again. The other countries also experienced peaks around the same time, but those peaks were smaller and their subsequent declines were less pronounced. The exception is Italy, which peaked in 1920 and has since reduced its alcohol consumption dramatically. The correlation coefficients indicate that every country except Italy exhibited a general upward trend until its peak; in Italy, a strong downward trend is clearly observable.


f)  Create a meaningful plot / figure with the dataset. Make sure to
    provide a figure caption (via the chunk options / Rmarkdown) and
    correctly label the figure.
    

```{r}
alc_plot_data <- alcohol_data %>%
  filter(Year == 2014) %>%
  rename(alcohol_consumption = `Alcohol consumption since 1890 (Alexander & Holmes, 2017)`)

alc_plot_data %>%
  ggplot(aes(x = alcohol_consumption, y = "")) + 
  geom_boxplot(outlier.shape = NA) +
  geom_point(color = "red") +
  labs(
    title = "alcohol consumption in high-income countries in 2014",
    x = "liters of pure alcohol per capita",
    y = ""
  )
```




## Final Note

Make sure to push all your commits and changes to GitHub before
submitting the exercise sheet.
